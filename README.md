
# Assignment 1 – Text Normalization and Token Frequency Analysis

## Files
- `normalize_text.py` – Main script for normalization, counting, and analysis
- `environment.yml` – Conda environment specification
- `README.md` – Project documentation
- `output/` – Generated outputs (token count files and plots; created automatically)
---

## Requirements
- Python 3.14
- Conda 
- Required Python packages are listed in `environment.yml`

To create and activate the environment:
```bash
conda env create -f environment.yml
conda activate 4nl3
```

## Generative AI Usage Disclosure (Required)

Generative AI tools were used **only for conceptual clarification, debugging guidance, and assistance with code structure and documentation wording**. All final code, decisions, and interpretations were written and verified by the student.

### AI Usage Details
- **Model:** ChatGPT 5.2
- **Provider:** OpenAI
- **Hardware type:** Cloud-based GPU/accelerator
- **Region of compute:** Unknown
- **Time used:** Approximately 2–3 hours total across multiple short interactions
- **How values were estimated:** Time was approximated based on active interaction duration during development and debugging
- **Estimated emissions:**  
  ~4.32 g CO₂ per query × ~25 queries ≈ **108 g CO₂**

